# Numerical_Optimization
These labs are about
> Linear Regression with 
- Batch gradient descent
- Mini batch gradient descent
- Stochastic gradient descent
> Applying batch gradient descent with different algorithms like
- Momentum based, NAG
- Adagrad, RMSProb, Adam
